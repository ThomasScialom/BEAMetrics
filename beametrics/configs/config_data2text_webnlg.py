import json
from beametrics.configs.config_base import ConfigBase
from beametrics.metrics.metric_reporter import _DEFAULT_METRIC_NAMES

class Data2textWebNLG(ConfigBase):
    def __init__(self):

        file_name = 'webnlg-data.json'
        file_name_processed = 'processed.data2text.webnlg'
        metric_names = _DEFAULT_METRIC_NAMES

        name_dataset = 'WebNLG-Eval'
        short_name_dataset = 'Web'
        languages = ["en"]
        task = "data2text"
        number_examples = 2007
        nb_refs = 3
        dimensions_definitions = {
            'fluency': "Rate the fluency of the text: Does the text sound fluent and natural? (1 - Not fluent, 2 - Medium, 3 - Fluent)",
            'grammar': "Rate the grammar and the spelling of the text: Is the text grammatical (no spelling or grammatical errors)? (1 - Ungrammatical, 2 - Medium, 3 - Grammatical)",
            'semantics': "Does the text correctly represent the meaning in the data? (1 - Incorrectly, 2 - Medium, 3 - Correctly)"
        }
        scale = "likert 1-3"
        source_eval_sets = "WebNLG"
        annotators = "English Speaker from https://www.crowdflower.com/ (See more on [the corresponding paper](English Speaker from https://www.crowdflower.com/)"
        additional_comments = "The evaluated texts are generated by automatic systems on WebNLG and evaluated on a likert scale from 1 to 3."
        sampled_from = "https://webnlg-challenge.loria.fr/files/webnlg-human-evaluation-results.pdf"
        citation = """@article{shimorina2019webnlg,
        title={WebNLG Challenge: Human Evaluation Results},
        author={Shimorina, Anastasia and Gardent, Claire and Narayan, Shashi and Perez-Beltrachini, Laura},
        year={2019}
}"""

        super().__init__(
            file_name=file_name,
            file_name_processed=file_name_processed,
            metric_names=metric_names,
            name_dataset=name_dataset,
            short_name_dataset=short_name_dataset,
            languages=languages,
            task=task,
            nb_refs=nb_refs,
            number_examples=number_examples,
            dimensions_definitions=dimensions_definitions,
            scale=scale,
            sampled_from=sampled_from,
            source_eval_sets=source_eval_sets,
            annotators=annotators,
            citation=citation,
            additional_comments=additional_comments
        )

    def format_file(
        self,
        path
    ):
        with open(path, "r") as f_r:
            temp_data = json.loads(f_r.read())

        d_data = {}
        for i, ex in enumerate(temp_data):
            ex['source'] = ex['source'].split('<br>')
            d_data[i] = ex
        return d_data